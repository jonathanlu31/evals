"""
GPQA: A Graduate-Level Google-Proof Q&A Benchmark
David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, Samuel R. Bowman
https://arxiv.org/abs/2311.12022

From OpenAI's simple-evals, but switch out the sampler for our samplers
"""

import argparse
import os
import re
from pathlib import Path

import jsonlines
from common import ANSWER_PATTERN_MULTICHOICE, _compute_stat


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("--outputs_path", type=Path, required=True)
    parser.add_argument("--results_path", type=Path, default=Path("./results"))
    parser.add_argument(
        "--bootstrap",
        type=int,
        default=0,
        help="Number of bootstrap iterations for confidence intervals",
    )
    return parser.parse_args()


def main():
    args = parse_args()

    with jsonlines.open(args.outputs_path) as reader:
        outputs = list(reader)

    for out in outputs:
        response_text = out["messages"][-1]["content"]
        correct_answer = out["correct_answer"]
        match = re.search(ANSWER_PATTERN_MULTICHOICE, response_text)
        extracted_answer = match.group(1) if match else None
        score = 1.0 if extracted_answer == correct_answer else 0.0
        out["score"] = score

    os.makedirs(os.path.dirname(args.results_path), exist_ok=True)
    with jsonlines.open(args.results_path, mode="w") as writer:
        for out in outputs:
            writer.write(out)

    scores = [p["score"] for p in outputs]
    print(_compute_stat(scores, "mean"), end=",")
    print(_compute_stat(scores, "std"))


if __name__ == "__main__":
    main()
