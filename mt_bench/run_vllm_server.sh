#!/bin/bash

# Make sure to start the vLLM server using serve_vllm.sh first

set -x

MODEL_DIR=${1}

cd "$(dirname "$0")"

python gen_api_answer.py --model $MODEL_DIR --openai-api-base http://localhost:8000/v1 --parallel 20
