# Evals

## Installation

```bash
pip install .
pip install ".[ifeval]"
```

## Usage

For each benchmark, use the provided scripts to run them

For larger models, use vLLM server

```bash
bash serve_vllm.sh <model_path> <num_gpus>
```

For reasoning models, you must use vLLM server, otherwise the response parsing will not work correctly and the evaluations will break.
